{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:52.363724Z",
     "iopub.status.busy": "2022-12-14T12:26:52.363466Z",
     "iopub.status.idle": "2022-12-14T12:26:54.305215Z",
     "shell.execute_reply": "2022-12-14T12:26:54.304527Z"
    },
    "id": "RsCV2oAS7gC_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 17:39:31.017394: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-18 17:39:31.222727: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-18 17:39:31.224579: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-18 17:39:32.299171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:root:TensorFlow Decision Forests 1.4.0 is compatible with the following TensorFlow Versions: ['2.12.0']. However, TensorFlow 2.12.1 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:54.310354Z",
     "iopub.status.busy": "2022-12-14T12:26:54.308974Z",
     "iopub.status.idle": "2022-12-14T12:26:54.313977Z",
     "shell.execute_reply": "2022-12-14T12:26:54.313392Z"
    },
    "id": "jZXB4o6Tlu0i"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "from IPython.core.magic import register_line_magic\n",
    "from IPython.display import Javascript\n",
    "from IPython.display import display as ipy_display\n",
    "\n",
    "# Some of the model training logs can cover the full\n",
    "# screen if not compressed to a smaller viewport.\n",
    "# This magic allows setting a max height for a cell.\n",
    "@register_line_magic\n",
    "def set_cell_height(size):\n",
    "  ipy_display(\n",
    "      Javascript(\"google.colab.output.setIframeHeight(0, true, {maxHeight: \" +\n",
    "                 str(size) + \"})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22996\n",
      "['carbocisteine', 'inhibit', 'respiratory', 'syncytial', 'virus', 'infection', 'human', 'tracheal', 'epithelial', 'cell', 'it', 'be', 'suggest', 'carbocisteine', 'may', 'inhibit', 'rs', 'virus', 'infection', 'reduce', 'expression', 'icam', 'rs', 'virus', 'receptor', 'it', 'may', 'also', 'modulate', 'airway', 'inflammation', 'rsirus', 'infection', 'respiratory_syncytial', 'tracheal_epithelial', 'it_be', 'rs_virus', 'expression_icam', 'rs_virus', 'airway_inflammation']\n",
      "8679\n",
      "['vitro', 'effect', 'human', 'cathelicidin', 'antimicrobial', 'peptide', 'll', 'dengue', 'virus', 'type', 'vitro', 'experiment', 'silico', 'analysis', 'suggest', 'll', 'inhibit', 'dengue', 'virus', 'type', 'denv', 'infection', 'replication', 'vero', 'e6', 'cell', 'bind', 'protein', 'human_cathelicidin', 'antimicrobial_peptide', 'dengue_virus', 'vitro_experiment', 'silico_analysis', 'll_inhibit', 'dengue_virus', 'denv_infection', 'vero_e6']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dataset_path = \"/home/ralf/IdeaProjects/LitBall-training/EXP-Title+TLDR/\"\n",
    "text_key = \"preprocessedText\"\n",
    "docs = []\n",
    "larr1 = []\n",
    "with open(dataset_path + \"ROTVRSV\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        d = json.loads(line)\n",
    "        docs.append(d[text_key])\n",
    "        larr1.append(d[\"label\"])\n",
    "\n",
    "tdocs = []\n",
    "larr2 = []\n",
    "with open(dataset_path + \"DENV\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        d = json.loads(line)\n",
    "        tdocs.append(d[text_key])\n",
    "        larr2.append(d[\"label\"])\n",
    "\n",
    "        # Tokenize the documents.\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "for idx in range(len(tdocs)):\n",
    "    tdocs[idx] = tdocs[idx].lower()  # Convert to lowercase.\n",
    "    tdocs[idx] = tokenizer.tokenize(tdocs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "tdocs = [[token for token in doc if not token.isnumeric()] for doc in tdocs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]\n",
    "tdocs = [[token for token in doc if len(token) > 1] for doc in tdocs]\n",
    "\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "delim = '_'\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=1, delimiter=delim)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if delim in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)\n",
    "for idx in range(len(tdocs)):\n",
    "    for token in bigram[tdocs[idx]]:\n",
    "        if delim in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            tdocs[idx].append(token)\n",
    "\n",
    "print(len(docs))\n",
    "print(docs[0][:500])\n",
    "print(len(tdocs))\n",
    "print(tdocs[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"preprocessedText\": \"acute kidney injury associate dengue virus infection review review narrative review aim update epidemiology aki associate dengue elucidate main pathophysiological mechanism discuss useful information prevention management ofaki patient dengue acute_kidney dengue_virus review_narrative review_aim pathophysiological_mechanism useful_information prevention_management\", \"label\": \"0\"}\n"
     ]
    }
   ],
   "source": [
    "in_memory_file1 = open('/tmp/t1', 'w')\n",
    "for i in range(len(docs)):\n",
    "    in_memory_file1.write(json.dumps({text_key: ' '.join(docs[i]), \"label\": larr1[i]}, ensure_ascii=True))\n",
    "    in_memory_file1.write('\\n')\n",
    "in_memory_file1.close()\n",
    "in_memory_file1 = open('/tmp/t1', 'r')\n",
    "#in_memory_file1 = open(dataset_path + \"DENV\")\n",
    "in_memory_file2 = open('/tmp/t3', 'w')\n",
    "for i in range(len(tdocs)):\n",
    "    in_memory_file2.write(json.dumps({text_key: ' '.join(tdocs[i]), \"label\": larr2[i]}, ensure_ascii=True))\n",
    "    in_memory_file2.write('\\n')\n",
    "    if i==500:\n",
    "        print(json.dumps({text_key: ' '.join(tdocs[i]), \"label\": larr2[i]}))\n",
    "in_memory_file2.close()\n",
    "in_memory_file2 = open('/tmp/t3', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:55.925820Z",
     "iopub.status.busy": "2022-12-14T12:26:55.925271Z",
     "iopub.status.idle": "2022-12-14T12:27:00.827053Z",
     "shell.execute_reply": "2022-12-14T12:27:00.826354Z"
    },
    "id": "uVN-j0E4Q1T3"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "trds = pd.read_json(in_memory_file1,\n",
    "                 dtype={text_key: str, \"label\": str},\n",
    "                lines=True\n",
    "                 )\n",
    "teds = pd.read_json(in_memory_file2,\n",
    "                 dtype={text_key: str, \"label\": str},\n",
    "                lines=True\n",
    "                 )\n",
    "tr_ds = tfdf.keras.pd_dataframe_to_tf_dataset(trds, label=\"label\")\n",
    "te_ds = tfdf.keras.pd_dataframe_to_tf_dataset(teds, label=\"label\")\n",
    "\n",
    "dataset_path = \"/home/ralf/IdeaProjects/LitBall-training/EXP-Title+TLDR/\"\n",
    "with open(dataset_path + \"DENV\") as file:\n",
    "    test_lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:27:00.831031Z",
     "iopub.status.busy": "2022-12-14T12:27:00.830774Z",
     "iopub.status.idle": "2022-12-14T12:27:00.919993Z",
     "shell.execute_reply": "2022-12-14T12:27:00.919392Z"
    },
    "id": "yqYDKTKdSPYw"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset1(example, label):\n",
    "    return {\"sentence\" : tf.strings.split(example[text_key])}, label\n",
    "\n",
    "def prepare_dataset2(s):\n",
    "    m = json.loads(s)\n",
    "    sp = tf.strings.split(m[\"preprocessedText\"])\n",
    "#    print(sp)\n",
    "#    m[\"prep\"] = tf.RaggedTensor.from_tensor(sp, ragged_rank=1)\n",
    "#    m[\"prep\"] = tf.constant(sp)\n",
    "    return m\n",
    "\n",
    "train_ds = tr_ds.map(prepare_dataset1)\n",
    "test_ds = te_ds.map(prepare_dataset1)\n",
    "#for features, label in test_ds:\n",
    "#    print(\"features:\", features)\n",
    "#    print(\"label:\", label)\n",
    "#    break\n",
    "    \n",
    "test_cases = list(map(prepare_dataset2, test_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:27:00.923884Z",
     "iopub.status.busy": "2022-12-14T12:27:00.923343Z",
     "iopub.status.idle": "2022-12-14T12:27:53.858309Z",
     "shell.execute_reply": "2022-12-14T12:27:53.857637Z"
    },
    "id": "mpxTtYo39wYZ"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpglageop1 as temporary training directory\n",
      "Warning: Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'sentence': tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64))}\n",
      "Label: Tensor(\"data_2:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'sentence': SemanticTensor(semantic=<Semantic.CATEGORICAL_SET: 4>, tensor=tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64)))}\n",
      "Training dataset read in 0:00:00.183608. Found 22996 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 20:26:58.180706: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [22996]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "[INFO 23-07-18 20:26:58.3652 CEST kernel.cc:773] Start Yggdrasil model training\n",
      "[INFO 23-07-18 20:26:58.3652 CEST kernel.cc:774] Collect training examples\n",
      "[INFO 23-07-18 20:26:58.3652 CEST kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 23-07-18 20:26:58.3658 CEST kernel.cc:393] Number of batches: 23\n",
      "[INFO 23-07-18 20:26:58.3659 CEST kernel.cc:394] Number of examples: 22996\n",
      "[INFO 23-07-18 20:26:58.4576 CEST data_spec_inference.cc:305] 51819 item(s) have been pruned (i.e. they are considered out of dictionary) for the column sentence (2000 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 23-07-18 20:26:58.5256 CEST kernel.cc:794] Training dataset:\n",
      "Number of records: 22996\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL_SET: 1 (50%)\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL_SET: 1 (50%)\n",
      "\t1: \"sentence\" CATEGORICAL_SET has-dict vocab-size:2001 num-oods:40213 (174.87%) most-frequent:\"<OOD>\" 40213 (174.87%)\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 23-07-18 20:26:58.5257 CEST kernel.cc:810] Configure learner\n",
      "[INFO 23-07-18 20:26:58.5259 CEST kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^sentence$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 1000\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO 23-07-18 20:26:58.5262 CEST kernel.cc:827] Deployment config:\n",
      "cache_path: \"/tmp/tmpglageop1/working_cache\"\n",
      "num_threads: 3\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 23-07-18 20:26:58.5268 CEST kernel.cc:889] Train model\n",
      "[INFO 23-07-18 20:26:58.5278 CEST random_forest.cc:416] Training random forest on 22996 example(s) and 1 feature(s).\n",
      "[INFO 23-07-18 20:27:04.1341 CEST random_forest.cc:802] Training of tree  1/1000 (tree index:1) done accuracy:0.733884 logloss:9.59178\n",
      "[INFO 23-07-18 20:27:15.9189 CEST random_forest.cc:802] Training of tree  7/1000 (tree index:6) done accuracy:0.756996 logloss:3.99562\n",
      "[INFO 23-07-18 20:27:27.4612 CEST random_forest.cc:802] Training of tree  13/1000 (tree index:13) done accuracy:0.783604 logloss:1.70494\n",
      "[INFO 23-07-18 20:27:38.8834 CEST random_forest.cc:802] Training of tree  19/1000 (tree index:18) done accuracy:0.801192 logloss:0.96346\n",
      "[INFO 23-07-18 20:27:50.5222 CEST random_forest.cc:802] Training of tree  25/1000 (tree index:24) done accuracy:0.811011 logloss:0.668622\n",
      "[INFO 23-07-18 20:28:02.2650 CEST random_forest.cc:802] Training of tree  31/1000 (tree index:30) done accuracy:0.817142 logloss:0.561291\n",
      "[INFO 23-07-18 20:28:14.1476 CEST random_forest.cc:802] Training of tree  37/1000 (tree index:36) done accuracy:0.82236 logloss:0.494223\n",
      "[INFO 23-07-18 20:28:26.3258 CEST random_forest.cc:802] Training of tree  43/1000 (tree index:42) done accuracy:0.825926 logloss:0.461182\n",
      "[INFO 23-07-18 20:28:37.9687 CEST random_forest.cc:802] Training of tree  49/1000 (tree index:48) done accuracy:0.829188 logloss:0.440293\n",
      "[INFO 23-07-18 20:28:49.6089 CEST random_forest.cc:802] Training of tree  55/1000 (tree index:54) done accuracy:0.832319 logloss:0.428047\n",
      "[INFO 23-07-18 20:29:01.0221 CEST random_forest.cc:802] Training of tree  61/1000 (tree index:60) done accuracy:0.834536 logloss:0.423428\n",
      "[INFO 23-07-18 20:29:12.8687 CEST random_forest.cc:802] Training of tree  67/1000 (tree index:66) done accuracy:0.835841 logloss:0.421254\n",
      "[INFO 23-07-18 20:29:24.7601 CEST random_forest.cc:802] Training of tree  73/1000 (tree index:72) done accuracy:0.838755 logloss:0.418365\n",
      "[INFO 23-07-18 20:29:36.6544 CEST random_forest.cc:802] Training of tree  79/1000 (tree index:78) done accuracy:0.839189 logloss:0.416143\n",
      "[INFO 23-07-18 20:29:48.8003 CEST random_forest.cc:802] Training of tree  85/1000 (tree index:85) done accuracy:0.84032 logloss:0.411181\n",
      "[INFO 23-07-18 20:30:00.6539 CEST random_forest.cc:802] Training of tree  91/1000 (tree index:91) done accuracy:0.84019 logloss:0.406434\n",
      "[INFO 23-07-18 20:30:12.2903 CEST random_forest.cc:802] Training of tree  97/1000 (tree index:96) done accuracy:0.84306 logloss:0.403142\n",
      "[INFO 23-07-18 20:30:23.8859 CEST random_forest.cc:802] Training of tree  103/1000 (tree index:102) done accuracy:0.841973 logloss:0.40285\n",
      "[INFO 23-07-18 20:30:36.0753 CEST random_forest.cc:802] Training of tree  109/1000 (tree index:108) done accuracy:0.842146 logloss:0.402498\n",
      "[INFO 23-07-18 20:30:48.2867 CEST random_forest.cc:802] Training of tree  115/1000 (tree index:114) done accuracy:0.842625 logloss:0.400603\n",
      "[INFO 23-07-18 20:30:59.3435 CEST random_forest.cc:802] Training of tree  121/1000 (tree index:120) done accuracy:0.842973 logloss:0.398743\n",
      "[INFO 23-07-18 20:31:12.4031 CEST random_forest.cc:802] Training of tree  127/1000 (tree index:126) done accuracy:0.843147 logloss:0.398333\n",
      "[INFO 23-07-18 20:31:25.7072 CEST random_forest.cc:802] Training of tree  133/1000 (tree index:132) done accuracy:0.843016 logloss:0.397869\n",
      "[INFO 23-07-18 20:31:38.4605 CEST random_forest.cc:802] Training of tree  139/1000 (tree index:138) done accuracy:0.84506 logloss:0.393607\n",
      "[INFO 23-07-18 20:31:51.1761 CEST random_forest.cc:802] Training of tree  145/1000 (tree index:144) done accuracy:0.844538 logloss:0.389049\n",
      "[INFO 23-07-18 20:32:03.6028 CEST random_forest.cc:802] Training of tree  151/1000 (tree index:150) done accuracy:0.84493 logloss:0.388898\n",
      "[INFO 23-07-18 20:32:16.8654 CEST random_forest.cc:802] Training of tree  157/1000 (tree index:156) done accuracy:0.84493 logloss:0.387209\n",
      "[INFO 23-07-18 20:32:29.6819 CEST random_forest.cc:802] Training of tree  163/1000 (tree index:162) done accuracy:0.845495 logloss:0.38715\n",
      "[INFO 23-07-18 20:32:42.0150 CEST random_forest.cc:802] Training of tree  169/1000 (tree index:168) done accuracy:0.845321 logloss:0.386922\n",
      "[INFO 23-07-18 20:32:54.5983 CEST random_forest.cc:802] Training of tree  175/1000 (tree index:174) done accuracy:0.845321 logloss:0.385266\n",
      "[INFO 23-07-18 20:33:06.9526 CEST random_forest.cc:802] Training of tree  181/1000 (tree index:180) done accuracy:0.846147 logloss:0.385017\n",
      "[INFO 23-07-18 20:33:19.2244 CEST random_forest.cc:802] Training of tree  187/1000 (tree index:186) done accuracy:0.846147 logloss:0.382103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 23-07-18 20:33:31.3440 CEST random_forest.cc:802] Training of tree  193/1000 (tree index:192) done accuracy:0.846582 logloss:0.381836\n",
      "[INFO 23-07-18 20:33:42.7524 CEST random_forest.cc:802] Training of tree  198/1000 (tree index:197) done accuracy:0.846539 logloss:0.38162\n",
      "[INFO 23-07-18 20:33:53.6396 CEST random_forest.cc:802] Training of tree  203/1000 (tree index:202) done accuracy:0.846234 logloss:0.381592\n",
      "[INFO 23-07-18 20:34:06.4087 CEST random_forest.cc:802] Training of tree  209/1000 (tree index:208) done accuracy:0.846886 logloss:0.381453\n",
      "[INFO 23-07-18 20:34:19.3246 CEST random_forest.cc:802] Training of tree  215/1000 (tree index:214) done accuracy:0.846452 logloss:0.38135\n",
      "[INFO 23-07-18 20:34:32.1344 CEST random_forest.cc:802] Training of tree  221/1000 (tree index:220) done accuracy:0.846539 logloss:0.381346\n",
      "[INFO 23-07-18 20:34:44.8770 CEST random_forest.cc:802] Training of tree  227/1000 (tree index:226) done accuracy:0.846712 logloss:0.381141\n",
      "[INFO 23-07-18 20:34:57.7836 CEST random_forest.cc:802] Training of tree  233/1000 (tree index:232) done accuracy:0.846539 logloss:0.380942\n",
      "[INFO 23-07-18 20:35:11.1725 CEST random_forest.cc:802] Training of tree  239/1000 (tree index:238) done accuracy:0.84706 logloss:0.380879\n",
      "[INFO 23-07-18 20:35:24.3845 CEST random_forest.cc:802] Training of tree  245/1000 (tree index:244) done accuracy:0.847321 logloss:0.380642\n",
      "[INFO 23-07-18 20:35:36.8763 CEST random_forest.cc:802] Training of tree  251/1000 (tree index:251) done accuracy:0.84793 logloss:0.380555\n",
      "[INFO 23-07-18 20:35:49.0065 CEST random_forest.cc:802] Training of tree  257/1000 (tree index:256) done accuracy:0.847365 logloss:0.380559\n",
      "[INFO 23-07-18 20:36:01.3592 CEST random_forest.cc:802] Training of tree  263/1000 (tree index:262) done accuracy:0.847452 logloss:0.380477\n",
      "[INFO 23-07-18 20:36:13.1002 CEST random_forest.cc:802] Training of tree  269/1000 (tree index:270) done accuracy:0.84706 logloss:0.38046\n",
      "[INFO 23-07-18 20:36:24.3764 CEST random_forest.cc:802] Training of tree  275/1000 (tree index:274) done accuracy:0.847104 logloss:0.380328\n",
      "[INFO 23-07-18 20:36:36.2382 CEST random_forest.cc:802] Training of tree  281/1000 (tree index:280) done accuracy:0.847234 logloss:0.380251\n",
      "[INFO 23-07-18 20:36:47.9176 CEST random_forest.cc:802] Training of tree  287/1000 (tree index:286) done accuracy:0.847582 logloss:0.380204\n",
      "[INFO 23-07-18 20:36:59.9538 CEST random_forest.cc:802] Training of tree  293/1000 (tree index:292) done accuracy:0.847843 logloss:0.380236\n",
      "[INFO 23-07-18 20:37:11.5426 CEST random_forest.cc:802] Training of tree  299/1000 (tree index:298) done accuracy:0.847539 logloss:0.380175\n",
      "[INFO 23-07-18 20:37:22.8239 CEST random_forest.cc:802] Training of tree  305/1000 (tree index:304) done accuracy:0.847887 logloss:0.38008\n",
      "[INFO 23-07-18 20:37:34.5460 CEST random_forest.cc:802] Training of tree  311/1000 (tree index:310) done accuracy:0.848191 logloss:0.380102\n",
      "[INFO 23-07-18 20:37:46.1779 CEST random_forest.cc:802] Training of tree  317/1000 (tree index:316) done accuracy:0.847669 logloss:0.380063\n",
      "[INFO 23-07-18 20:37:56.9817 CEST random_forest.cc:802] Training of tree  323/1000 (tree index:322) done accuracy:0.848104 logloss:0.379918\n",
      "[INFO 23-07-18 20:38:08.6424 CEST random_forest.cc:802] Training of tree  329/1000 (tree index:328) done accuracy:0.847495 logloss:0.379845\n",
      "[INFO 23-07-18 20:38:20.5805 CEST random_forest.cc:802] Training of tree  335/1000 (tree index:334) done accuracy:0.848191 logloss:0.379804\n",
      "[INFO 23-07-18 20:38:32.0387 CEST random_forest.cc:802] Training of tree  341/1000 (tree index:340) done accuracy:0.848452 logloss:0.379729\n",
      "[INFO 23-07-18 20:38:43.6875 CEST random_forest.cc:802] Training of tree  347/1000 (tree index:346) done accuracy:0.848191 logloss:0.37971\n",
      "[INFO 23-07-18 20:38:55.2616 CEST random_forest.cc:802] Training of tree  353/1000 (tree index:352) done accuracy:0.848365 logloss:0.37977\n",
      "[INFO 23-07-18 20:39:05.2758 CEST random_forest.cc:802] Training of tree  358/1000 (tree index:357) done accuracy:0.848365 logloss:0.379759\n",
      "[INFO 23-07-18 20:39:17.2394 CEST random_forest.cc:802] Training of tree  364/1000 (tree index:363) done accuracy:0.848713 logloss:0.379772\n",
      "[INFO 23-07-18 20:39:28.9690 CEST random_forest.cc:802] Training of tree  370/1000 (tree index:369) done accuracy:0.84893 logloss:0.379715\n",
      "[INFO 23-07-18 20:39:41.1511 CEST random_forest.cc:802] Training of tree  376/1000 (tree index:375) done accuracy:0.848452 logloss:0.379753\n",
      "[INFO 23-07-18 20:39:53.2221 CEST random_forest.cc:802] Training of tree  382/1000 (tree index:381) done accuracy:0.84893 logloss:0.379727\n",
      "[INFO 23-07-18 20:40:04.9183 CEST random_forest.cc:802] Training of tree  388/1000 (tree index:387) done accuracy:0.848539 logloss:0.379724\n",
      "[INFO 23-07-18 20:40:17.1761 CEST random_forest.cc:802] Training of tree  394/1000 (tree index:393) done accuracy:0.848452 logloss:0.379643\n",
      "[INFO 23-07-18 20:40:29.4895 CEST random_forest.cc:802] Training of tree  400/1000 (tree index:399) done accuracy:0.848408 logloss:0.379572\n",
      "[INFO 23-07-18 20:40:40.8815 CEST random_forest.cc:802] Training of tree  406/1000 (tree index:406) done accuracy:0.848452 logloss:0.379549\n",
      "[INFO 23-07-18 20:40:52.6514 CEST random_forest.cc:802] Training of tree  412/1000 (tree index:411) done accuracy:0.848539 logloss:0.379619\n",
      "[INFO 23-07-18 20:41:04.5550 CEST random_forest.cc:802] Training of tree  418/1000 (tree index:417) done accuracy:0.848539 logloss:0.379534\n",
      "[INFO 23-07-18 20:41:16.4392 CEST random_forest.cc:802] Training of tree  424/1000 (tree index:424) done accuracy:0.848539 logloss:0.379536\n",
      "[INFO 23-07-18 20:41:27.9756 CEST random_forest.cc:802] Training of tree  430/1000 (tree index:429) done accuracy:0.848148 logloss:0.37952\n",
      "[INFO 23-07-18 20:41:39.9715 CEST random_forest.cc:802] Training of tree  436/1000 (tree index:435) done accuracy:0.847756 logloss:0.379539\n",
      "[INFO 23-07-18 20:41:51.7747 CEST random_forest.cc:802] Training of tree  442/1000 (tree index:441) done accuracy:0.848365 logloss:0.379498\n",
      "[INFO 23-07-18 20:42:03.5588 CEST random_forest.cc:802] Training of tree  448/1000 (tree index:447) done accuracy:0.848669 logloss:0.379497\n",
      "[INFO 23-07-18 20:42:15.3630 CEST random_forest.cc:802] Training of tree  454/1000 (tree index:454) done accuracy:0.848626 logloss:0.379464\n",
      "[INFO 23-07-18 20:42:27.2598 CEST random_forest.cc:802] Training of tree  460/1000 (tree index:459) done accuracy:0.849278 logloss:0.379473\n",
      "[INFO 23-07-18 20:42:38.5657 CEST random_forest.cc:802] Training of tree  466/1000 (tree index:465) done accuracy:0.849061 logloss:0.379443\n",
      "[INFO 23-07-18 20:42:50.3051 CEST random_forest.cc:802] Training of tree  472/1000 (tree index:471) done accuracy:0.848626 logloss:0.379585\n",
      "[INFO 23-07-18 20:43:02.5865 CEST random_forest.cc:802] Training of tree  478/1000 (tree index:477) done accuracy:0.848974 logloss:0.379571\n",
      "[INFO 23-07-18 20:43:14.7425 CEST random_forest.cc:802] Training of tree  484/1000 (tree index:483) done accuracy:0.84893 logloss:0.379474\n",
      "[INFO 23-07-18 20:43:26.7428 CEST random_forest.cc:802] Training of tree  490/1000 (tree index:489) done accuracy:0.848756 logloss:0.379506\n",
      "[INFO 23-07-18 20:43:38.9835 CEST random_forest.cc:802] Training of tree  496/1000 (tree index:495) done accuracy:0.848408 logloss:0.379575\n",
      "[INFO 23-07-18 20:43:50.4917 CEST random_forest.cc:802] Training of tree  502/1000 (tree index:501) done accuracy:0.84893 logloss:0.379553\n",
      "[INFO 23-07-18 20:44:02.2207 CEST random_forest.cc:802] Training of tree  508/1000 (tree index:507) done accuracy:0.849278 logloss:0.37956\n",
      "[INFO 23-07-18 20:44:13.4879 CEST random_forest.cc:802] Training of tree  514/1000 (tree index:513) done accuracy:0.849322 logloss:0.379608\n",
      "[INFO 23-07-18 20:44:25.0457 CEST random_forest.cc:802] Training of tree  520/1000 (tree index:519) done accuracy:0.849409 logloss:0.379496\n",
      "[INFO 23-07-18 20:44:36.4936 CEST random_forest.cc:802] Training of tree  526/1000 (tree index:525) done accuracy:0.849017 logloss:0.379453\n",
      "[INFO 23-07-18 20:44:48.4419 CEST random_forest.cc:802] Training of tree  532/1000 (tree index:531) done accuracy:0.849278 logloss:0.379469\n",
      "[INFO 23-07-18 20:44:59.7679 CEST random_forest.cc:802] Training of tree  538/1000 (tree index:537) done accuracy:0.849322 logloss:0.379466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 23-07-18 20:45:11.2017 CEST random_forest.cc:802] Training of tree  544/1000 (tree index:543) done accuracy:0.849452 logloss:0.379448\n",
      "[INFO 23-07-18 20:45:21.4276 CEST random_forest.cc:802] Training of tree  549/1000 (tree index:548) done accuracy:0.849148 logloss:0.379417\n",
      "[INFO 23-07-18 20:45:33.9050 CEST random_forest.cc:802] Training of tree  555/1000 (tree index:554) done accuracy:0.84893 logloss:0.379431\n",
      "[INFO 23-07-18 20:45:45.8900 CEST random_forest.cc:802] Training of tree  561/1000 (tree index:560) done accuracy:0.849061 logloss:0.379409\n",
      "[INFO 23-07-18 20:45:57.5001 CEST random_forest.cc:802] Training of tree  567/1000 (tree index:566) done accuracy:0.84967 logloss:0.379353\n",
      "[INFO 23-07-18 20:46:09.0106 CEST random_forest.cc:802] Training of tree  573/1000 (tree index:572) done accuracy:0.850061 logloss:0.379368\n",
      "[INFO 23-07-18 20:46:20.6372 CEST random_forest.cc:802] Training of tree  579/1000 (tree index:578) done accuracy:0.849713 logloss:0.37928\n",
      "[INFO 23-07-18 20:46:32.3817 CEST random_forest.cc:802] Training of tree  585/1000 (tree index:585) done accuracy:0.850061 logloss:0.379249\n",
      "[INFO 23-07-18 20:46:42.5366 CEST random_forest.cc:802] Training of tree  590/1000 (tree index:589) done accuracy:0.850148 logloss:0.379262\n",
      "[INFO 23-07-18 20:46:54.2196 CEST random_forest.cc:802] Training of tree  596/1000 (tree index:595) done accuracy:0.849539 logloss:0.379179\n",
      "[INFO 23-07-18 20:47:05.5147 CEST random_forest.cc:802] Training of tree  602/1000 (tree index:601) done accuracy:0.850278 logloss:0.377813\n",
      "[INFO 23-07-18 20:47:17.3497 CEST random_forest.cc:802] Training of tree  608/1000 (tree index:607) done accuracy:0.850235 logloss:0.377771\n",
      "[INFO 23-07-18 20:47:29.5562 CEST random_forest.cc:802] Training of tree  614/1000 (tree index:613) done accuracy:0.849756 logloss:0.377749\n",
      "[INFO 23-07-18 20:47:40.9898 CEST random_forest.cc:802] Training of tree  620/1000 (tree index:619) done accuracy:0.850104 logloss:0.377709\n",
      "[INFO 23-07-18 20:47:53.2370 CEST random_forest.cc:802] Training of tree  626/1000 (tree index:625) done accuracy:0.849756 logloss:0.37773\n",
      "[INFO 23-07-18 20:48:05.1369 CEST random_forest.cc:802] Training of tree  632/1000 (tree index:631) done accuracy:0.849756 logloss:0.377719\n",
      "[INFO 23-07-18 20:48:16.9983 CEST random_forest.cc:802] Training of tree  638/1000 (tree index:637) done accuracy:0.850278 logloss:0.377712\n",
      "[INFO 23-07-18 20:48:28.7770 CEST random_forest.cc:802] Training of tree  644/1000 (tree index:643) done accuracy:0.850061 logloss:0.377705\n",
      "[INFO 23-07-18 20:48:40.2172 CEST random_forest.cc:802] Training of tree  650/1000 (tree index:649) done accuracy:0.850104 logloss:0.377669\n",
      "[INFO 23-07-18 20:48:52.1499 CEST random_forest.cc:802] Training of tree  656/1000 (tree index:655) done accuracy:0.850191 logloss:0.377621\n",
      "[INFO 23-07-18 20:49:04.0041 CEST random_forest.cc:802] Training of tree  662/1000 (tree index:661) done accuracy:0.849756 logloss:0.377653\n",
      "[INFO 23-07-18 20:49:15.7169 CEST random_forest.cc:802] Training of tree  668/1000 (tree index:667) done accuracy:0.849756 logloss:0.377638\n",
      "[INFO 23-07-18 20:49:27.7389 CEST random_forest.cc:802] Training of tree  674/1000 (tree index:673) done accuracy:0.849887 logloss:0.377584\n",
      "[INFO 23-07-18 20:49:39.8404 CEST random_forest.cc:802] Training of tree  680/1000 (tree index:679) done accuracy:0.849496 logloss:0.377586\n",
      "[INFO 23-07-18 20:49:52.4499 CEST random_forest.cc:802] Training of tree  686/1000 (tree index:685) done accuracy:0.849713 logloss:0.377553\n",
      "[INFO 23-07-18 20:50:03.9762 CEST random_forest.cc:802] Training of tree  692/1000 (tree index:691) done accuracy:0.849887 logloss:0.377518\n",
      "[INFO 23-07-18 20:50:15.8474 CEST random_forest.cc:802] Training of tree  698/1000 (tree index:698) done accuracy:0.850017 logloss:0.37751\n",
      "[INFO 23-07-18 20:50:27.6182 CEST random_forest.cc:802] Training of tree  704/1000 (tree index:703) done accuracy:0.849539 logloss:0.377446\n",
      "[INFO 23-07-18 20:50:39.1037 CEST random_forest.cc:802] Training of tree  710/1000 (tree index:709) done accuracy:0.849843 logloss:0.377412\n",
      "[INFO 23-07-18 20:50:50.3485 CEST random_forest.cc:802] Training of tree  716/1000 (tree index:715) done accuracy:0.850104 logloss:0.377342\n",
      "[INFO 23-07-18 20:51:01.9188 CEST random_forest.cc:802] Training of tree  722/1000 (tree index:721) done accuracy:0.850148 logloss:0.377396\n",
      "[INFO 23-07-18 20:51:13.4244 CEST random_forest.cc:802] Training of tree  728/1000 (tree index:727) done accuracy:0.850409 logloss:0.377346\n",
      "[INFO 23-07-18 20:51:25.0896 CEST random_forest.cc:802] Training of tree  734/1000 (tree index:733) done accuracy:0.850322 logloss:0.377401\n",
      "[INFO 23-07-18 20:51:36.5231 CEST random_forest.cc:802] Training of tree  740/1000 (tree index:739) done accuracy:0.850365 logloss:0.377396\n",
      "[INFO 23-07-18 20:51:48.2716 CEST random_forest.cc:802] Training of tree  746/1000 (tree index:745) done accuracy:0.850322 logloss:0.377406\n",
      "[INFO 23-07-18 20:52:00.2803 CEST random_forest.cc:802] Training of tree  752/1000 (tree index:751) done accuracy:0.850409 logloss:0.377431\n",
      "[INFO 23-07-18 20:52:11.6990 CEST random_forest.cc:802] Training of tree  758/1000 (tree index:757) done accuracy:0.850278 logloss:0.377408\n",
      "[INFO 23-07-18 20:52:23.4713 CEST random_forest.cc:802] Training of tree  764/1000 (tree index:763) done accuracy:0.850017 logloss:0.377406\n",
      "[INFO 23-07-18 20:52:35.0370 CEST random_forest.cc:802] Training of tree  770/1000 (tree index:769) done accuracy:0.850017 logloss:0.37739\n",
      "[INFO 23-07-18 20:52:47.0096 CEST random_forest.cc:802] Training of tree  776/1000 (tree index:775) done accuracy:0.850626 logloss:0.377356\n",
      "[INFO 23-07-18 20:52:58.9883 CEST random_forest.cc:802] Training of tree  782/1000 (tree index:781) done accuracy:0.85067 logloss:0.377334\n",
      "[INFO 23-07-18 20:53:10.7208 CEST random_forest.cc:802] Training of tree  788/1000 (tree index:787) done accuracy:0.850409 logloss:0.377377\n",
      "[INFO 23-07-18 20:53:22.5769 CEST random_forest.cc:802] Training of tree  794/1000 (tree index:793) done accuracy:0.850017 logloss:0.377303\n",
      "[INFO 23-07-18 20:53:33.2760 CEST random_forest.cc:802] Training of tree  799/1000 (tree index:798) done accuracy:0.8498 logloss:0.377288\n",
      "[INFO 23-07-18 20:53:45.6550 CEST random_forest.cc:802] Training of tree  805/1000 (tree index:804) done accuracy:0.850017 logloss:0.377302\n",
      "[INFO 23-07-18 20:53:57.5277 CEST random_forest.cc:802] Training of tree  811/1000 (tree index:811) done accuracy:0.849843 logloss:0.377325\n",
      "[INFO 23-07-18 20:54:08.8214 CEST random_forest.cc:802] Training of tree  817/1000 (tree index:816) done accuracy:0.850148 logloss:0.377277\n",
      "[INFO 23-07-18 20:54:20.5541 CEST random_forest.cc:802] Training of tree  823/1000 (tree index:822) done accuracy:0.849583 logloss:0.37729\n",
      "[INFO 23-07-18 20:54:32.1871 CEST random_forest.cc:802] Training of tree  829/1000 (tree index:828) done accuracy:0.84993 logloss:0.377248\n",
      "[INFO 23-07-18 20:54:44.2525 CEST random_forest.cc:802] Training of tree  835/1000 (tree index:834) done accuracy:0.850583 logloss:0.377239\n",
      "[INFO 23-07-18 20:54:55.7405 CEST random_forest.cc:802] Training of tree  841/1000 (tree index:840) done accuracy:0.850278 logloss:0.377283\n",
      "[INFO 23-07-18 20:55:07.2148 CEST random_forest.cc:802] Training of tree  847/1000 (tree index:846) done accuracy:0.850061 logloss:0.377261\n",
      "[INFO 23-07-18 20:55:17.5171 CEST random_forest.cc:802] Training of tree  852/1000 (tree index:851) done accuracy:0.850278 logloss:0.377222\n",
      "[INFO 23-07-18 20:55:29.7833 CEST random_forest.cc:802] Training of tree  858/1000 (tree index:857) done accuracy:0.850539 logloss:0.377218\n",
      "[INFO 23-07-18 20:55:41.4565 CEST random_forest.cc:802] Training of tree  864/1000 (tree index:863) done accuracy:0.850191 logloss:0.377173\n",
      "[INFO 23-07-18 20:55:53.8530 CEST random_forest.cc:802] Training of tree  870/1000 (tree index:870) done accuracy:0.850496 logloss:0.377156\n",
      "[INFO 23-07-18 20:56:05.3372 CEST random_forest.cc:802] Training of tree  876/1000 (tree index:875) done accuracy:0.85067 logloss:0.377125\n",
      "[INFO 23-07-18 20:56:17.3579 CEST random_forest.cc:802] Training of tree  882/1000 (tree index:881) done accuracy:0.850235 logloss:0.377085\n",
      "[INFO 23-07-18 20:56:29.0113 CEST random_forest.cc:802] Training of tree  888/1000 (tree index:887) done accuracy:0.850061 logloss:0.37705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 23-07-18 20:56:40.7727 CEST random_forest.cc:802] Training of tree  894/1000 (tree index:893) done accuracy:0.85067 logloss:0.376986\n",
      "[INFO 23-07-18 20:56:52.8694 CEST random_forest.cc:802] Training of tree  900/1000 (tree index:899) done accuracy:0.850844 logloss:0.376934\n",
      "[INFO 23-07-18 20:57:04.5511 CEST random_forest.cc:802] Training of tree  906/1000 (tree index:905) done accuracy:0.8508 logloss:0.376972\n",
      "[INFO 23-07-18 20:57:16.6800 CEST random_forest.cc:802] Training of tree  912/1000 (tree index:911) done accuracy:0.851452 logloss:0.376939\n",
      "[INFO 23-07-18 20:57:28.7919 CEST random_forest.cc:802] Training of tree  918/1000 (tree index:917) done accuracy:0.851452 logloss:0.376903\n",
      "[INFO 23-07-18 20:57:40.3947 CEST random_forest.cc:802] Training of tree  924/1000 (tree index:923) done accuracy:0.852409 logloss:0.3769\n",
      "[INFO 23-07-18 20:57:51.8202 CEST random_forest.cc:802] Training of tree  930/1000 (tree index:929) done accuracy:0.852148 logloss:0.37688\n",
      "[INFO 23-07-18 20:58:03.3867 CEST random_forest.cc:802] Training of tree  936/1000 (tree index:935) done accuracy:0.852105 logloss:0.376882\n",
      "[INFO 23-07-18 20:58:14.9158 CEST random_forest.cc:802] Training of tree  942/1000 (tree index:941) done accuracy:0.852105 logloss:0.376886\n",
      "[INFO 23-07-18 20:58:27.2739 CEST random_forest.cc:802] Training of tree  948/1000 (tree index:947) done accuracy:0.851626 logloss:0.376933\n",
      "[INFO 23-07-18 20:58:38.7755 CEST random_forest.cc:802] Training of tree  954/1000 (tree index:953) done accuracy:0.851844 logloss:0.376928\n",
      "[INFO 23-07-18 20:58:50.5176 CEST random_forest.cc:802] Training of tree  960/1000 (tree index:959) done accuracy:0.851713 logloss:0.376959\n",
      "[INFO 23-07-18 20:59:02.8750 CEST random_forest.cc:802] Training of tree  966/1000 (tree index:965) done accuracy:0.85167 logloss:0.376949\n",
      "[INFO 23-07-18 20:59:14.3830 CEST random_forest.cc:802] Training of tree  972/1000 (tree index:971) done accuracy:0.851539 logloss:0.376965\n",
      "[INFO 23-07-18 20:59:26.3034 CEST random_forest.cc:802] Training of tree  978/1000 (tree index:977) done accuracy:0.851452 logloss:0.376961\n",
      "[INFO 23-07-18 20:59:38.2261 CEST random_forest.cc:802] Training of tree  984/1000 (tree index:983) done accuracy:0.851322 logloss:0.376916\n",
      "[INFO 23-07-18 20:59:50.0941 CEST random_forest.cc:802] Training of tree  990/1000 (tree index:989) done accuracy:0.851105 logloss:0.376956\n",
      "[INFO 23-07-18 21:00:01.7631 CEST random_forest.cc:802] Training of tree  996/1000 (tree index:995) done accuracy:0.851061 logloss:0.376991\n",
      "[INFO 23-07-18 21:00:08.1970 CEST random_forest.cc:802] Training of tree  1000/1000 (tree index:999) done accuracy:0.851061 logloss:0.376986\n",
      "[INFO 23-07-18 21:00:08.1982 CEST random_forest.cc:882] Final OOB metrics: accuracy:0.851061 logloss:0.376986\n",
      "[INFO 23-07-18 21:00:08.4154 CEST kernel.cc:926] Export model in log directory: /tmp/tmpglageop1 with prefix 0d3c77f6bd534c6d\n",
      "[INFO 23-07-18 21:00:09.1674 CEST kernel.cc:944] Save model in resources\n",
      "[INFO 23-07-18 21:00:09.1975 CEST abstract_model.cc:849] Model self evaluation:\n",
      "Number of predictions (without weights): 22996\n",
      "Number of predictions (with weights): 22996\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.851061  CI95[W][0.847145 0.854912]\n",
      "LogLoss: : 0.376986\n",
      "ErrorRate: : 0.148939\n",
      "\n",
      "Default Accuracy: : 0.609367\n",
      "Default LogLoss: : 0.66903\n",
      "Default ErrorRate: : 0.390633\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "   0      1     2\n",
      "0  0      0     0\n",
      "1  0  12534  1479\n",
      "2  0   1946  7037\n",
      "Total: 22996\n",
      "\n",
      "One vs other classes:\n",
      "\n",
      "[INFO 23-07-18 21:00:09.5153 CEST kernel.cc:1243] Loading model from path /tmp/tmpglageop1/model/ with prefix 0d3c77f6bd534c6d\n",
      "[INFO 23-07-18 21:00:16.5856 CEST decision_forest.cc:660] Model loaded with 1000 root(s), 1272306 node(s), and 1 input feature(s).\n",
      "[INFO 23-07-18 21:00:16.5857 CEST abstract_model.cc:1311] Engine \"RandomForestGeneric\" built\n",
      "[INFO 23-07-18 21:00:16.5864 CEST kernel.cc:1075] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:33:18.508716\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 21:00:17.149000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [22996]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f33165010>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%set_cell_height 300\n",
    "\n",
    "# Specify the model.\n",
    "model_1 = tfdf.keras.RandomForestModel(num_trees=1000, verbose=2, num_threads=3)\n",
    "\n",
    "# Train the model.\n",
    "model_1.fit(x=train_ds, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:27:53.861879Z",
     "iopub.status.busy": "2022-12-14T12:27:53.861292Z",
     "iopub.status.idle": "2022-12-14T12:27:54.395342Z",
     "shell.execute_reply": "2022-12-14T12:27:54.394656Z"
    },
    "id": "cpf-wHl094S1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 08:43:30.492649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [8679]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 8s 909ms/step - loss: 0.0000e+00 - accuracy: 0.9010\n",
      "BinaryCrossentropyloss: 0.0\n",
      "Accuracy: 0.9010254740715027\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(metrics=[\"accuracy\"])\n",
    "evaluation = model_1.evaluate(test_ds, batch_size=None)\n",
    "\n",
    "print(f\"BinaryCrossentropyloss: {evaluation[0]}\")\n",
    "print(f\"Accuracy: {evaluation[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:27:54.399169Z",
     "iopub.status.busy": "2022-12-14T12:27:54.398503Z",
     "iopub.status.idle": "2022-12-14T12:27:54.837481Z",
     "shell.execute_reply": "2022-12-14T12:27:54.836829Z"
    },
    "id": "OnTTtBNmjpo7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = model_1.make_inspector().training_logs()\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Out-of-bag accuracy\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 8s 853ms/step\n",
      "cut: 0.25, acc: 0.6163152436916696, prec: 0.40212497748964526, rec: 0.9955416852429781, f1: 0.5728578758337608\n",
      "cut: 0.3, acc: 0.7052655835925797, prec: 0.46697420842944015, rec: 0.992866696388765, f1: 0.6351968054763263\n",
      "cut: 0.35, acc: 0.7762415024772439, prec: 0.5366090975431769, rec: 0.9835042353990192, f1: 0.6943657538558389\n",
      "cut: 0.39999999999999997, acc: 0.8261320428620809, prec: 0.6016620498614959, rec: 0.9683459652251449, f1: 0.7421834956432598\n",
      "cut: 0.44999999999999996, acc: 0.870491992164996, prec: 0.6793844180827188, rec: 0.9447168970129292, f1: 0.7903767251025737\n",
      "cut: 0.49999999999999994, acc: 0.9010254637631063, prec: 0.7568671121009651, rec: 0.9090503789567543, f1: 0.826007696981973\n",
      "cut: 0.5499999999999999, acc: 0.9164650305334716, prec: 0.8288561525129983, rec: 0.8528756130182791, f1: 0.8406943528894749\n",
      "cut: 0.5999999999999999, acc: 0.917732457656412, prec: 0.8855269793242562, rec: 0.7828800713330362, f1: 0.8310459062943683\n",
      "cut: 0.6499999999999999, acc: 0.9013711257057264, prec: 0.9220937309799148, rec: 0.6754346856888096, f1: 0.7797220792588779\n",
      "cut: 0.7, acc: 0.8791335407304989, prec: 0.9522727272727273, rec: 0.5604101649576461, f1: 0.7055851810272242\n",
      "cut: 0.7499999999999999, acc: 0.8503283788454891, prec: 0.9636542239685658, rec: 0.43736067766384307, f1: 0.6016559337626495\n"
     ]
    }
   ],
   "source": [
    "p = model_1.predict(test_ds)\n",
    "\n",
    "#Fish for best cut\n",
    "for cut in np.arange(0.25, .8, .05):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    N = len(p)\n",
    "    for i in range(N):\n",
    "        tru = test_cases[i][\"label\"] == '1'\n",
    "        prd = p[i] > cut\n",
    "        if tru and prd == tru:\n",
    "            tp = tp + 1\n",
    "        if tru and prd != tru:\n",
    "            fn = fn + 1\n",
    "        if tru == False and prd == tru:\n",
    "            tn = tn + 1\n",
    "        if tru == False and prd != tru:\n",
    "            fp = fp + 1\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    print(\"cut: {}, acc: {}, prec: {}, rec: {}, f1: {}\".format(cut, (tp+tn)/N, precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.0, n = 6525, tru: 378\n",
      "c: 0.05, n = 6396, tru: 378\n",
      "c: 0.1, n = 5885, tru: 377\n",
      "c: 0.15000000000000002, n = 4983, tru: 376\n",
      "c: 0.2, n = 4009, tru: 374\n",
      "c: 0.25, n = 3139, tru: 368\n",
      "c: 0.30000000000000004, n = 2379, tru: 351\n",
      "c: 0.35000000000000003, n = 1765, tru: 323\n",
      "c: 0.4, n = 1261, tru: 281\n",
      "c: 0.45, n = 785, tru: 209\n"
     ]
    }
   ],
   "source": [
    "cut = 55\n",
    "N = len(p)\n",
    "with open(\"/home/ralf//IdeaProjects/LitBall-training/pred.json\", \"w\") as file:\n",
    "    for c in np.arange(0., .5, .05):\n",
    "        s = 0\n",
    "        t = 0\n",
    "        for i in range(N):\n",
    "            tru = test_cases[i][\"label\"] == '1'\n",
    "            val = int((p[i]+0.005) * 100)\n",
    "            pred = False\n",
    "            if val > cut:\n",
    "                pred = True\n",
    "            elif val > 100*c:\n",
    "                s = s+1\n",
    "                if tru:\n",
    "                    t = t+1\n",
    "        print(\"c: {}, n = {}, tru: {}\".format(c, s, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intermediate_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
